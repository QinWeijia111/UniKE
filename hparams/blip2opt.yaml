# Model
device: 0
alg_name: "TPATCHER"
name: hugging_cache/opt-2.7b
model_name: blip2
model_class: Blip2OPT
tokenizer_class: GPT2Tokenizer
tokenizer_name: hugging_cache/opt-2.7b
inner_params: []


tp_layers:
  'opt_model.model.decoder.layers.31.fc1': 'output'
  'opt_model.model.decoder.layers.31.fc2': 'input'

  'opt_model.model.decoder.layers.30.fc1': 'output'
  'opt_model.model.decoder.layers.30.fc2': 'input'

  'opt_model.model.decoder.layers.29.fc1': 'output'
  'opt_model.model.decoder.layers.29.fc2': 'input'

icv_layers: 
- 'opt_model.model.decoder.layers.31.mlp_handler'
- 'opt_model.model.decoder.layers.30.mlp_handler'

icv_layer_num: 1
preset_icv_alpha: False
icv_alpha: 0.9

# Method
alg: "TPATCHER"
lr: 1e-6
edit_lr: 6e-3
lr_lr: 4e-4
lr_scale: 1.0
seed: 42
cedit: 0.1
iedit: 0.1
cloc: 1.0
cbase: 1.0
dropout: 0.0
train_base: False
no_grad_layers: null
one_sided: False
n_hidden: 1
hidden_dim: null
init: id
norm: True
combine: True
x_only: False
delta_only: False
act: relu
rank: 1920
mlp_class: IDMLP
shared: True
archive: null

# Train
batch_size: 1
model_save_pt: 5000
silent: False
max_epochs: 10
max_iters: 50000
log_interval: 100
eval_log_interval: 1000
final_eval: True
val_interval: 5000
early_stop_patience: 20000
early_stop_key: "loss/total_edit_val"
eval_only: False
half: False
debug: False
save: False
verbose: True
max_norm: 40.0


val_batch_size: 1
accumulate_bs: 2
val_steps: 500 # only for debug
# opt: SGD
icv_opt: Adam
tp_opt: SGD
grad_clip: 100.

# Output
results_dir: ./results

# Multimodal
qformer_checkpoint: hugging_cache/blip2_pretrained_opt2.7b.pth
qformer_name_or_path: ./hugging_cache/bert-base-uncased
state_dict_file: ./hugging_cache/eva_vit_g.pth


# image
coco_image: ../
rephrase_image: ../


# TP params
max_add_neuron_num: 25
freeze_model: True
freeze_k: 0
freeze_a: 0
memory_size: 40000
memory_loss: 'non_use'
amplify_v: 1
activate_loss: 'non_use'
act_margin_val: 0.0
margin_val1: 3
margin_val2: 3
hyperparams_nn: True
hyperparams_nn_count: 40
icv_feature_dim: 80


# Continue
continuous: True
continuous_sample: 1


# multi-task
multi_task: False
add_icv_layer: True
icv_lr: 2e-1
icv_locality_use_pre_res: True
force_train_icv: True

do_clip_norm: False
max_epochs_icv: 8
max_epochs_tp: 10

alpha_lr: 1e-10
alpha_model_ckpt: ./results/models/TPATCHER/blip2_alpha_caption_1.pth
# alpha_model_ckpt: ./results/models/TPATCHER/blip2_alpha_1.pth
